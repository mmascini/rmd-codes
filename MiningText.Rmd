---
title: "Mining MMpub"
author: "Marcello Mascini"
date: "4/24/2022"
output: html_document
---
# setup options chunk 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#activate libraries

```{r txt_lib, echo=TRUE}
library(pdftools)
library(tm) 
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
library(tidytext)
library(janeaustenr)
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(tibble)
library(writexl)


```

# import csv file with first row "Art" without any blank lines and strange symbol

```{r text_file, echo=TRUE}
allPDF <- read.csv(file = "file.csv", header = TRUE)
```


#Art is the name of the column 


```{r unest_token, echo=TRUE}
pdf_T<- allPDF %>%  unnest_tokens(word, Art)

```

#Remove stop words such as “the”, “of”, “to”, and so forth in English

```{r remove_stop, echo=TRUE}
data(stop_words)
tidyT <- pdf_T %>% anti_join(stop_words)

```

#find the most common words in all the books as a whole.

```{r tidy, echo=TRUE}
tidySort <-tidyT %>% count(word, sort = TRUE) 
print(tidySort[1:20,])


```

#Plot words change filter number according to the previous step

```{r plotwords, echo=TRUE}
library(ggplot2)
tidyT %>%
  count(word, sort = TRUE) %>%
  filter(n > 100) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)
```

#wordcloud plot

```{r cloud, echo=TRUE}
library(wordcloud)
tidyT %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 50))
```


#Split using two words changing the n = we can work with 3 words (trigram) ect
##Art is the name of the column

```{r Two_words, echo=TRUE}

library(tidytext)
library(tidyr)

pdf_2T<- allPDF %>%  unnest_tokens(bigram, Art, token = "ngrams", n = 2)
T2w<-pdf_2T %>%count(bigram, sort = TRUE)
print(T2w[1:20,])


```

#working with 2 words by removing “stop-words”
# https://www.tidytextmining.com/ngrams.html

```{r remove_two, echo=TRUE}

bigrams_separated <- pdf_2T %>%
  separate(bigram, c("word1", "word2"), sep = " ")


bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)


# new bigram counts:
bigram_counts <- bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

print(bigram_counts[1:20,])


```


#reunite  words after cleaning 

```{r reuniteword, echo=TRUE}
bigrams_united <- bigrams_filtered %>%
  unite(bigram, word1, word2, sep = " ")%>%count(bigram, sort = TRUE)

print(bigrams_united[1:20,])
```

#Split using triwords changing the n = we can work with 3 words (trigram) ect
#Art is the name of the column

```{r trigram, echo=TRUE}

pdf_3T<- allPDF %>%  unnest_tokens(trigram, Art, token = "ngrams", n = 3)
T3<- pdf_3T %>%count(trigram, sort = TRUE)

print(T3[1:20,])


```


#tri separated

```{r trisep, echo=TRUE}
trigrams_separated <- pdf_3T %>%
  separate(trigram, c("word1", "word2","word3"), sep = " ")


trigrams_filtered <- trigrams_separated %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>%
  filter(!word3 %in% stop_words$word)


# new trigram counts:
trigram_counts <- trigrams_filtered %>% 
  count(word1, word2, word3, sort = TRUE)


print(trigram_counts[1:20,])


```


#reunite  words after cleaning

```{r triunite, echo=TRUE}
trigrams_united <- trigrams_filtered %>%
  unite(trigram, word1, word2, word3, sep = " ")%>%count(trigram, sort = TRUE)
 
print(trigrams_united[1:20,])

```


#Split using 2-3-4-5-6 words changing the n Art is the name of the column


```{r Tall, echo=TRUE}
pdf_2T<- allPDF %>%  unnest_tokens(bigram, Art, token = "ngrams", n = 2)
table2T<-pdf_2T %>%count(bigram, sort = TRUE)

pdf_3T<- allPDF %>%  unnest_tokens(threegram, Art, token = "ngrams", n = 3)
table3T<-pdf_3T %>%count(threegram, sort = TRUE)

pdf_4T<- allPDF %>%  unnest_tokens(fourgram, Art, token = "ngrams", n = 4)
table4T<-pdf_4T %>%count(fourgram, sort = TRUE)

pdf_5T<- allPDF %>%  unnest_tokens(fivegram, Art, token = "ngrams", n = 5)
table5T<-pdf_5T %>%count(fivegram, sort = TRUE)

pdf_6T<- allPDF %>%  unnest_tokens(sixgram, Art, token = "ngrams", n = 6)
table6T<-pdf_6T %>%count(sixgram, sort = TRUE)

pdf_7T<- allPDF %>%  unnest_tokens(sevengram, Art, token = "ngrams", n = 7)
table7T<-pdf_7T %>%count(sevengram, sort = TRUE)

print(table2T[1:20,])
print(table3T[1:20,])
print(table4T[1:20,])
print(table5T[1:20,])
print(table6T[1:20,])
print(table7T[1:20,])


tableT<-list(table2T, table3T, table4T, table5T, table6T, table7T)

write_xlsx(tableT, "tableT.xlsx")


```


